{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring AWS data with python and pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://acinn.uibk.ac.at/sites/all/themes/imgi/images/acinn_logo.png\" width=\"20%\"  align=\"right\">\n",
    "\n",
    "This is a simple [jupyter notebook](http://jupyter.org/) created to illustrate its enormous potential for interactive data exploration and teaching. In this example we are going to explore meteorological data obtained at Zhadang Glacier, Tibetan Plateau.\n",
    "\n",
    "**Author**: [Fabien Maussion](http://fabienmaussion.info/)\n",
    "\n",
    "**Date**: 17.06.2016\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The automatic weather station (AWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/u/20930277/do_not_delete/aws_tibet.jpg?raw=1\" width=\"50%\"  align=\"right\">\n",
    "\n",
    "The station is installed on the Zhadang glacier surface since 2009. \n",
    "\n",
    "- Location: 30.47153°N, 90.64534°E\n",
    "- Altitude: 5665 m a.s.l.\n",
    "- Variables: SWin, SWOut, LWOut, NetRad, Temp, RH, Wind speed & direction, SR50, Pressure, Precipitation, Ice temp\n",
    "\n",
    "\n",
    "Related publications: \n",
    "\n",
    "[Maussion et al., (2011)](https://dl.dropboxusercontent.com/u/20930277/do_not_delete/Maussion_etal_2011.pdf), [Mölg et al., (2012)](http://www.the-cryosphere.net/6/1445/2012/tc-6-1445-2012.pdf), [Zhang et al., (2013)](http://www.cryoscience.net/pub/pdf/2013jg_zhang.pdf), [Huintjes et al., (2015)](http://www.bioone.org/doi/abs/10.1657/AAAR0014-073).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the [pandas](http://pandas.pydata.org/) library for the IO and the data crunching, [matplotlib](http://matplotlib.org/) and [seaborn](https://web.stanford.edu/~mwaskom/software/seaborn/) for the visualisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules we need\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# some cosmetic defaults\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('talk')\n",
    "pd.options.display.max_rows = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('aws_data_zhadang_UTC+6.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df is a new variable we just created. It a short name for [DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). A dataframe is a table, very similar to the data model of Excel (but muche more flexible and powerful). Let's simply print it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of a DataFrame can be extracted and plotted very easily: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TEMP'].plot();\n",
    "plt.ylabel('°C');\n",
    "plt.title('2m air temperature');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['SWIN', 'SWOUT']].plot();\n",
    "plt.ylabel('W m$^{-2}$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to make more elaborated plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(5, 5));\n",
    "df.plot(x='SWIN', y='SWOUT', kind='scatter', ax=ax);\n",
    "ax.set_xlim([0, 1500]);\n",
    "ax.set_ylim([0, 1500]);\n",
    "ax.set_aspect('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the clear clusters corresponding to the albedos of fresh snow and of ice, which also have a clearly defined physical limit. There are several outliers, related to the covering of the inciming SW sensor by snowfall.\n",
    "\n",
    "With the help of seaborn, making even more sophisticated plots is very easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.jointplot(x='WINDDIR', y='WINDSPEED', data=df, stat_func=None, xlim=[0, 360], ylim=[0, 17]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We detect at least two preferred wind directions (north-westerly -from North West to South East-, and southerly -from South to North, or downglacier-). The highest wind speeds are observed when the winds are north-westerly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data crunching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas excels at selecting, grouping, and analysing data. Let's start with building daily averages of our hourly records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = df.resample('D').mean();\n",
    "# Compute the daily albedo and filter out spurious values\n",
    "df_avg['ALBEDO'] = df_avg['SWOUT'] / df_avg['SWIN']\n",
    "df_avg['ALBEDO'] = np.where(df_avg['ALBEDO'] < 0.9, df_avg['ALBEDO'], np.NaN)\n",
    "df_avg[['SWIN', 'SWOUT', 'ALBEDO']].plot(secondary_y='ALBEDO');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute monthly averages is as easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = df.resample('MS').mean();\n",
    "df_avg['NETRAD'].plot();\n",
    "plt.title('Net radiation')\n",
    "plt.ylabel('W m$^{-2}$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so is the computation of the daily cycle for a specific month of the year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mon = df.loc[df.index.month == 7]\n",
    "df_cycle = df_mon.groupby(df_mon.index.hour).mean()\n",
    "df_cycle[['SWIN', 'SWOUT', 'TEMP']].plot(secondary_y='TEMP');\n",
    "plt.title('Daily cycle of SW fluxes and Temperature in July');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find much more examples and tutorials in the repository of the \"Cryopshere and the Climate System\" lecture [here](https://github.com/fmaussion/teaching/tree/master/ss_2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
